"""
Great Expectations checkpoints are combinations of data source, expectation suite, and
validation operators configuration that can be used to run Great Expectations actions.
Checkpoints are the preferred deployment of validation configuration; you can read more about
setting up checkpoints [at the Great Expectation
docs](https://docs.greatexpectations.io/en/latest/tutorials/getting_started/set_up_your_first_checkpoint.html#set-up-your-first-checkpoint).

You can use these task library tasks to interact with your Great Expectations checkpoint from a
Prefect flow.
"""
import prefect
from prefect import Task
from prefect.artifacts import create_markdown

from prefect.engine import signals
from prefect.utilities.tasks import defaults_from_attrs

import great_expectations as ge

from typing import Optional


class RunGreatExpectationsCheckpoint(Task):
    """
    Task for running a Great Expectations checkpoint.

    Example using the GE getting started tutorial:
    https://github.com/superconductive/ge_tutorials/tree/main/ge_getting_started_tutorial

    This is a parameterized flow for building the `batch_kwargs` to be passed into the task.

    ```python
    from prefect import task, Flow, Parameter
    from prefect.tasks.great_expectations import RunGreatExpectationsCheckpoint


    # Define checkpoint task
    checkpoint_task = RunGreatExpectationsCheckpoint()


    # Task for retrieving batch kwargs including csv dataset
    @task
    def get_batch_kwargs(datasource_name, dataset):
        dataset = ge.read_csv(dataset)
        return {"dataset": dataset, "datasource": datasource_name}


    with Flow("ge_test") as flow:
        datasource_name = Parameter("datasource_name")
        dataset = Parameter("dataset")
        batch_kwargs = get_batch_kwargs(datasource_name, dataset)

        expectation_suite_name = Parameter("expectation_suite_name")
        checkpoint_name = Parameter("checkpoint_name")
        checkpoint_task(
            checkpoint_name=checkpoint_name,
            batch_kwargs=batch_kwargs,
            expectation_suite_name=expectation_suite_name,
        )

    flow.run(
        parameters={
            "datasource_name": "data__dir",
            "dataset": "data/yellow_tripdata_sample_2019-01.csv",
            "expectation_suite_name": "yellow_tripdata_sample_2019-01.warning",
            "checkpoint_name": "action_list_operator",
        },
    )
    ```


    Args:
        - checkpoint_name (str, optional): the name of the checkpoint; should match the filename of
            the checkpoint without .py
        - context (DataContext, optional): an in-memory GE DataContext object. e.g.
            `ge.data_context.DataContext()` If not provided then `context_root_dir` will be used to
            look for one.
        - assets_to_validate (list, optional): A list of assets to validate when running the
            validation operator. If not provided then `batch_kwargs` and `expectation_suite_name`
            will be used if context is provided. Also, if not provided and
            `get_checkpoint_from_context` is True then the assets will be loaded from that context.
        - batch_kwargs (dict, optional): a dictionary of batch kwargs to be used when validating
            assets.
        - expectation_suite_name (str, optional): the name of an expectation suite to be used when
            validating assets.
        - get_checkpoint_from_context (bool, optional): get the checkpoint from context. Defaults to
            `False`
        - context_root_dir (str, optional): the absolute or relative path to the directory holding
            your `great_expectations.yml`
        - runtime_environment (dict, optional): a dictionary of great expectation config key-value
            pairs to overwrite your config in `great_expectations.yml`
        - run_name (str, optional): the name of this  Great Expectation validation run; defaults to
            the task slug
        - run_info_at_end (bool, optional): add run info to the end of the artifact generated by this
            task. Defaults to `True`.
        - disable_markdown_artifact (bool, optional): toggle the posting of a markdown artifact from
            this tasks. Defaults to `False`.
        - **kwargs (dict, optional): additional keyword arguments to pass to the Task constructor
    """

    def __init__(
        self,
        checkpoint_name: str = None,
        context: "ge.DataContext" = None,
        assets_to_validate: list = None,
        batch_kwargs: dict = None,
        expectation_suite_name: str = None,
        get_checkpoint_from_context: bool = False,
        context_root_dir: str = None,
        runtime_environment: Optional[dict] = None,
        run_name: str = None,
        run_info_at_end: bool = True,
        disable_markdown_artifact: bool = False,
        **kwargs
    ):
        self.checkpoint_name = checkpoint_name
        self.context = context
        self.assets_to_validate = assets_to_validate
        self.batch_kwargs = batch_kwargs
        self.expectation_suite_name = expectation_suite_name
        self.get_checkpoint_from_context = get_checkpoint_from_context
        self.context_root_dir = context_root_dir
        self.runtime_environment = runtime_environment or dict()
        self.run_name = run_name
        self.run_info_at_end = run_info_at_end
        self.disable_markdown_artifact = disable_markdown_artifact

        super().__init__(**kwargs)

    @defaults_from_attrs(
        "checkpoint_name",
        "context",
        "assets_to_validate",
        "batch_kwargs",
        "expectation_suite_name",
        "get_checkpoint_from_context",
        "context_root_dir",
        "runtime_environment",
        "run_name",
        "run_info_at_end",
        "disable_markdown_artifact",
    )
    def run(
        self,
        checkpoint_name: str = None,
        context: "ge.DataContext" = None,
        assets_to_validate: list = None,
        batch_kwargs: dict = None,
        expectation_suite_name: str = None,
        get_checkpoint_from_context: bool = False,
        context_root_dir: str = None,
        runtime_environment: Optional[dict] = None,
        run_name: str = None,
        run_info_at_end: bool = True,
        disable_markdown_artifact: bool = False,
    ):
        """
        Task run method.

        Args:
            - checkpoint_name (str, optional): the name of the checkpoint; should match the filename of
                the checkpoint without .py
            - context (DataContext, optional): an in-memory GE DataContext object. e.g.
                `ge.data_context.DataContext()` If not provided then `context_root_dir` will be used to
                look for one.
            - assets_to_validate (list, optional): A list of assets to validate when running the
                validation operator. If not provided then `batch_kwargs` and `expectation_suite_name`
                will be used if context is provided. Also, if not provided and
                `get_checkpoint_from_context` is True then the assets will be loaded from that context.
            - batch_kwargs (dict, optional): a dictionary of batch kwargs to be used when validating
                assets.
            - expectation_suite_name (str, optional): the name of an expectation suite to be used when
                validating assets.
            - get_checkpoint_from_context (bool, optional): get the checkpoint from context. Defaults to
                `False`
            - context_root_dir (str, optional): the absolute or relative path to the directory holding
                your `great_expectations.yml`
            - runtime_environment (dict, optional): a dictionary of great expectation config key-value
                pairs to overwrite your config in `great_expectations.yml`
            - run_name (str, optional): the name of this  Great Expectation validation run; defaults to
                the task slug
            - run_info_at_end (bool, optional): add run info to the end of the artifact generated by this
                task. Defaults to `True`.
            - disable_markdown_artifact (bool, optional): toggle the posting of a markdown artifact from
                this tasks. Defaults to `False`.

        Raises:
            - 'signals.VALIDATIONFAIL' if the validation was not a success

        Returns:
            - result
                ('great_expectations.validation_operators.types.validation_operator_result.ValidationOperatorResult'):
                The Great Expectations metadata returned from the validation

        """
        if checkpoint_name is None:
            raise ValueError("You must provide the checkpoint name.")

        runtime_environment = runtime_environment or dict()

        # Load context if not provided directly
        if not context:
            context = ge.DataContext(
                context_root_dir=context_root_dir,
                runtime_environment=runtime_environment,
            )

        # if assets are not provided directly through `assets_to_validate` then they need be loaded
        #   if the checkpoint is being loaded from the context then load suite and batch from there
        #   otherwise get batch from `batch_kwargs` and `expectation_suite_name`
        if not assets_to_validate:
            assets_to_validate = []
            if get_checkpoint_from_context:
                ge_checkpoint = context.get_checkpoint(checkpoint_name)

                for batch in ge_checkpoint["batches"]:
                    batch_kwargs = batch["batch_kwargs"]
                    for suite_name in batch["expectation_suite_names"]:
                        suite = context.get_expectation_suite(suite_name)
                        batch = context.get_batch(batch_kwargs, suite)
                        assets_to_validate.append(batch)
            else:
                assets_to_validate.append(
                    context.get_batch(batch_kwargs, expectation_suite_name)
                )

        # Run validation operator
        results = context.run_validation_operator(
            checkpoint_name or ge_checkpoint["validation_operator_name"],
            assets_to_validate=assets_to_validate,
            run_id={"run_name": run_name or prefect.context.get("task_slug")},
        )

        if results.success is False:
            raise signals.VALIDATIONFAIL(result=results)

        # Generate artifact markdown
        if not disable_markdown_artifact:
            run_info_at_end = True
            validation_results_page_renderer = (
                ge.render.renderer.ValidationResultsPageRenderer(
                    run_info_at_end=run_info_at_end
                )
            )
            rendered_document_content_list = (
                validation_results_page_renderer.render_validation_operator_result(
                    validation_operator_result=results
                )
            )
            markdown_artifact = " ".join(
                ge.render.view.DefaultMarkdownPageView().render(
                    rendered_document_content_list
                )
            )

            create_markdown(markdown_artifact)

        return results
